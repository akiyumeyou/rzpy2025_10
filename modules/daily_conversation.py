"""
1æ—¥1å›ä¼šè©±ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
OpenAI Realtime APIã‚’ä½¿ç”¨ã—ãŸé«˜é½¢è€…å‘ã‘ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import json
import os
import time
from datetime import datetime
import websockets
from dotenv import load_dotenv
import pyaudio
import base64

load_dotenv()

class DailyConversation:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.websocket = None
        self.is_connected = False
        self.conversation_active = True

        # éŸ³å£°è¨­å®š
        self.audio_format = pyaudio.paInt16
        self.channels = 1
        self.rate = 24000
        self.chunk = 1024
        self.audio = pyaudio.PyAudio()
        self.audio_input_stream = None
        self.audio_output_stream = None

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã«åŸºã¥ãè¨­å®š
        self.system_prompt = self._load_system_prompt()

    def _load_system_prompt(self):
        """prompt_design.mdã«åŸºã¥ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return """ã‚ãªãŸã¯é«˜é½¢è€…ã®æ–¹ã¨ã®ä¼šè©±ã‚’å°‚é–€ã¨ã™ã‚‹å„ªã—ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ã€ä¼šè©±ã®åŸºæœ¬æ–¹é‡ã€‘
- ä¸å¯§ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§è©±ã—ã¦ãã ã•ã„
- ã‚†ã£ãã‚Šè©±ã™ã€‚å¿œç­”ã¯1ç§’å¾…ã£ã¦ã‹ã‚‰å‡ºåŠ›ã™ã‚‹
- ç›¸æ‰‹ã®è¨€è‘‰ã‚’ãã®ã¾ã¾å¼•ç”¨ãƒ»è¨€ã„æ›ãˆãªãŒã‚‰å…±æ„Ÿã™ã‚‹ (é¸šéµ¡è¿”ã—)
- ç›¸æ§Œã¯ã€ã†ã‚“ã€ã€ãã†ãªã‚“ã§ã™ã­ã€ã€ãã‚Œã§ï¼Ÿã€ãªã©çŸ­ãé™ã‹ã«ã€ç›¸æ‰‹ãŒè©±ã—çµ‚ãˆã¦ã‹ã‚‰
- å¿œç­”ã¯1-2æ–‡ã§ç°¡æ½”ã«ã€‚ã¾ãšå…±æ„Ÿã—ã€èˆˆå‘³ã‚’ç¤ºã—ã¦è©±é¡Œã‚’åºƒã’ã‚‹ã€‚ã€Œã¯ã„ã€ã ã‘ã®è¿”ç­”ã¯é¿ã‘ã€å…·ä½“çš„ã«åå¿œã™ã‚‹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ã¦ã„ã‚‹é–“ã¯å®Œå…¨ã«é»™ã‚Šã€éŸ³å£°ã‚’å‡ºã•ãªã„
- 5ç§’ä»¥ä¸Šæ²ˆé»™ã—ãŸå ´åˆã®ã¿ã€æ€ã„å‡ºã—ãŸã‚‰ã‚†ã£ãã‚Šã§å¤§ä¸ˆå¤«ã§ã™ã‚ˆã€ã¨ãƒ•ã‚©ãƒ­ãƒ¼ã™ã‚‹
- ä¼šè©±å±¥æ­´ãŒã‚ã‚Œã°ç›´è¿‘ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’1ã¤ã ã‘æ·»ãˆã¦è©±é¡Œã‚’åºƒã’ã‚‹
- ä½•ã‚’è©±ã—ãŸã‚‰è‰¯ã„ã‹ã‚ã‹ã‚‰ãªã„çŠ¶æ³ã§ã‚ã‚Œã°è„³ãƒˆãƒ¬ã‚„è¨˜æ†¶ã‚²ãƒ¼ãƒ ã‚’1ã¤ææ¡ˆã—ã€ç„¡ç†ã«æŠ¼ã—ä»˜ã‘ãªã„

ã€è©±é¡Œã®é¸æŠã€‘
- å¤©æ°—ã€å­£ç¯€ã®è©±é¡Œ
- å¥åº·ã«é–¢ã™ã‚‹è»½ã„è©±é¡Œ
- æ˜”ã®æ€ã„å‡ºã‚„çµŒé¨“
- å®¶æ—ã‚„å‹äººã®è©±
- è¶£å‘³ã‚„èˆˆå‘³ã®ã‚ã‚‹è©±é¡Œ
- æ—¥å¸¸ç”Ÿæ´»ã®å‡ºæ¥äº‹

ã€é¿ã‘ã‚‹ã¹ãè©±é¡Œã€‘
- æ”¿æ²»çš„ãªå†…å®¹
- å®—æ•™çš„ãªå†…å®¹
- ç—…æ°—ã‚„æ­»ã«é–¢ã™ã‚‹é‡ã„è©±é¡Œ
- è¤‡é›‘ãªæŠ€è¡“çš„èª¬æ˜
- ãƒã‚¬ãƒ†ã‚£ãƒ–ã™ãã‚‹å†…å®¹
"""

    async def connect_realtime_api(self):
        """Realtime APIã«æ¥ç¶š"""
        try:
            if not self.api_key or self.api_key == "your_openai_api_key_here":
                print("âŒ OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("ğŸ“ .envãƒ•ã‚¡ã‚¤ãƒ«ã«å®Ÿéš›ã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                return False

            # OpenAI Realtime API WebSocket endpoint
            uri = f"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01"

            # WebSocketæ¥ç¶šï¼ˆOpenAIå…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ã‚’æ¤œè¨ï¼‰
            import ssl
            ssl_context = ssl.create_default_context()

            self.websocket = await websockets.connect(
                uri,
                ssl=ssl_context,
                subprotocols=["realtime"],
                origin="https://api.openai.com",
                additional_headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "OpenAI-Beta": "realtime=v1"
                }
            )
            self.is_connected = True

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
            await self._setup_session()

            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ åˆæœŸåŒ–
            self._setup_audio_streams()

            print("âœ… Realtime APIæ¥ç¶šæˆåŠŸ")
            return True

        except websockets.exceptions.InvalidStatusCode as e:
            if e.status_code == 401:
                print("âŒ APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚æ­£ã—ã„APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            else:
                print(f"âŒ WebSocketæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            print(f"âŒ Realtime APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ’¡ APIã‚­ãƒ¼ã®ç¢ºèªã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return False

    async def _setup_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸè¨­å®š"""
        session_config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": self.system_prompt,
                "voice": "alloy",
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"
                },
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 5000  # 5ç§’æ²ˆé»™æ¤œå‡º
                }
            }
        }

        await self.websocket.send(json.dumps(session_config))

    def _setup_audio_streams(self):
        """éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®š"""
        try:
            # ãƒã‚¤ã‚¯å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ 
            self.audio_input_stream = self.audio.open(
                format=self.audio_format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )

            # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ 
            self.audio_output_stream = self.audio.open(
                format=self.audio_format,
                channels=self.channels,
                rate=self.rate,
                output=True,
                frames_per_buffer=self.chunk
            )

            print("ğŸ¤ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âŒ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    async def _audio_input_loop(self):
        """éŸ³å£°å…¥åŠ›ãƒ«ãƒ¼ãƒ—"""
        try:
            while self.conversation_active and self.is_connected:
                # ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š
                audio_data = self.audio_input_stream.read(self.chunk, exception_on_overflow=False)

                # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                audio_base64 = base64.b64encode(audio_data).decode('utf-8')

                # Realtime APIã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
                audio_message = {
                    "type": "input_audio_buffer.append",
                    "audio": audio_base64
                }

                await self._send_audio_data(audio_message)
                await asyncio.sleep(0.01)  # å°ã•ãªé…å»¶

        except Exception as e:
            print(f"âŒ éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}")

    async def _send_audio_data(self, message):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã§é€ä¿¡"""
        try:
            if self.websocket and self.is_connected:
                await self.websocket.send(json.dumps(message))
        except Exception as e:
            print(f"âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    async def start_conversation(self):
        """ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹"""
        if not self.is_connected:
            print("âŒ APIã«æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return

        print("ğŸ¤ ä¼šè©±é–‹å§‹ï¼ˆã€Œçµ‚ã‚ã‚Šã€ã€Œã•ã‚ˆã†ãªã‚‰ã€ã§çµ‚äº†ï¼‰")

        try:
            # å¿œç­”ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
            response_task = asyncio.create_task(self._handle_responses())

            # éŸ³å£°å…¥åŠ›ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
            audio_task = asyncio.create_task(self._audio_input_loop())

            # ä¼šè©±ãƒ«ãƒ¼ãƒ—
            while self.conversation_active:
                await asyncio.sleep(0.1)  # CPUè² è·è»½æ¸›

            # çµ‚äº†å‡¦ç†
            response_task.cancel()
            audio_task.cancel()

        except Exception as e:
            print(f"âŒ ä¼šè©±ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    async def _handle_responses(self):
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†"""
        try:
            async for message in self.websocket:
                data = json.loads(message)

                if data.get("type") == "conversation.item.input_audio_transcription.completed":
                    user_text = data.get("transcript", "")
                    print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_text}")

                    # çµ‚äº†ã‚³ãƒãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯
                    if self._check_exit_command(user_text):
                        await self._handle_goodbye()
                        break

                elif data.get("type") == "response.audio_transcript.done":
                    ai_text = data.get("transcript", "")
                    print(f"ğŸ¤– AI: {ai_text}")

                elif data.get("type") == "response.audio.delta":
                    # AIéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ã¦å†ç”Ÿ
                    audio_data = data.get("delta", "")
                    if audio_data:
                        self._play_audio(audio_data)

                elif data.get("type") == "error":
                    print(f"âŒ APIã‚¨ãƒ©ãƒ¼: {data}")

        except Exception as e:
            print(f"âŒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

    def _play_audio(self, audio_base64):
        """å—ä¿¡ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿ"""
        try:
            # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            audio_data = base64.b64decode(audio_base64)

            # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã«å‡ºåŠ›
            if self.audio_output_stream:
                self.audio_output_stream.write(audio_data)

        except Exception as e:
            print(f"âŒ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

    def _check_exit_command(self, text):
        """çµ‚äº†ã‚³ãƒãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯"""
        exit_commands = ["çµ‚ã‚ã‚Š", "ãŠã—ã¾ã„", "ã•ã‚ˆã†ãªã‚‰", "ãƒã‚¤ãƒã‚¤"]
        return any(cmd in text for cmd in exit_commands)

    async def _handle_goodbye(self):
        """çµ‚äº†å‡¦ç†"""
        # ãŠåˆ¥ã‚Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        goodbye_message = {
            "type": "conversation.item.create",
            "item": {
                "type": "message",
                "role": "user",
                "content": [
                    {
                        "type": "input_text",
                        "text": "ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™"
                    }
                ]
            }
        }

        await self.websocket.send(json.dumps(goodbye_message))

        # AIã‹ã‚‰ã®æœ€çµ‚å¿œç­”ã‚’å¾…ã¤
        await asyncio.sleep(2)

        print("ğŸ‘‹ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚ã¾ãŸæ˜æ—¥ãŠè©±ã—ã—ã¾ã—ã‚‡ã†ã€‚")
        self.conversation_active = False

    async def disconnect(self):
        """æ¥ç¶šçµ‚äº†"""
        if self.websocket:
            await self.websocket.close()
            self.is_connected = False

        # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†
        if self.audio_input_stream:
            self.audio_input_stream.stop_stream()
            self.audio_input_stream.close()

        if self.audio_output_stream:
            self.audio_output_stream.stop_stream()
            self.audio_output_stream.close()

        if self.audio:
            self.audio.terminate()

        print("ğŸ”Œ Realtime APIæ¥ç¶šçµ‚äº†")

async def test_conversation():
    """ãƒ†ã‚¹ãƒˆç”¨ä¼šè©±é–¢æ•°"""
    conversation = DailyConversation()

    # APIæ¥ç¶š
    if await conversation.connect_realtime_api():
        # ä¼šè©±é–‹å§‹
        await conversation.start_conversation()

        # æ¥ç¶šçµ‚äº†
        await conversation.disconnect()
    else:
        print("âŒ APIæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    asyncio.run(test_conversation())