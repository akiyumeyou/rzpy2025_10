"""
ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
Whisper + GPT-4o + TTS
è‡ªå‹•èµ·å‹•ãƒ»éŸ³å£°ã®ã¿ãƒ»UIãªã—
"""

import asyncio
import io
import tempfile
import pyaudio
import wave
import openai
import os
import sys
import time
import subprocess
import struct
import math
from datetime import datetime

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.config import Config
from modules.logger import get_logger

logger = get_logger(__name__)

class SimpleVoiceChat:
    """ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        # OpenAIè¨­å®š
        self.client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)

        # éŸ³å£°è¨­å®š
        self.chunk = 512
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.record_seconds = 0.5  # 0.5ç§’å˜ä½ã§éŒ²éŸ³

        self.audio = pyaudio.PyAudio()
        self.running = False
        self.conversation_history = []

        print("ğŸ¤ ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def detect_speech(self, audio_data) -> bool:
        """éŸ³å£°æ¤œçŸ¥ï¼ˆéŸ³é‡ãƒ™ãƒ¼ã‚¹ï¼‰"""
        # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’16bitæ•´æ•°ã«å¤‰æ›
        fmt = '<' + ('h' * (len(audio_data) // 2))
        audio_ints = struct.unpack(fmt, audio_data)

        # RMSè¨ˆç®—
        sum_squares = sum(x * x for x in audio_ints)
        rms = math.sqrt(sum_squares / len(audio_ints))

        # é–¾å€¤ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
        threshold = 500
        return rms > threshold

    async def listen_for_speech(self) -> bytes:
        """éŸ³å£°ã‚’èã„ã¦éŒ²éŸ³"""
        print("ğŸ‘‚ éŸ³å£°ã‚’å¾…æ©Ÿä¸­... (è©±ã—ã‹ã‘ã¦ãã ã•ã„)")

        stream = self.audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )

        frames = []
        is_recording = False
        silence_count = 0
        max_silence = 15  # ç´„0.75ç§’ã®ç„¡éŸ³ã§çµ‚äº†

        try:
            while True:
                data = stream.read(self.chunk, exception_on_overflow=False)

                speech_detected = self.detect_speech(data)

                if speech_detected:
                    if not is_recording:
                        print("ğŸ¤ éŸ³å£°æ¤œçŸ¥é–‹å§‹")
                        is_recording = True
                        frames = []

                    frames.append(data)
                    silence_count = 0

                elif is_recording:
                    frames.append(data)  # ç„¡éŸ³éƒ¨åˆ†ã‚‚å°‘ã—éŒ²éŸ³
                    silence_count += 1

                    if silence_count > max_silence:
                        print("ğŸ”‡ éŸ³å£°æ¤œçŸ¥çµ‚äº†")
                        break

                # éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å‡¦ç†
                await asyncio.sleep(0.01)

        finally:
            stream.stop_stream()
            stream.close()

        if frames:
            return b''.join(frames)
        return b''

    async def transcribe_audio(self, audio_data: bytes) -> str:
        """éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        if not audio_data:
            return ""

        try:
            print("ğŸ”„ éŸ³å£°èªè­˜ä¸­...")

            import io

            buffer = io.BytesIO()
            with wave.open(buffer, 'wb') as wav_file:
                wav_file.setnchannels(self.channels)
                wav_file.setsampwidth(self.audio.get_sample_size(self.format))
                wav_file.setframerate(self.rate)
                wav_file.writeframes(audio_data)

            buffer.seek(0)

            transcript = self.client.audio.transcriptions.create(
                model="whisper-1",
                file=("audio.wav", buffer, "audio/wav"),
                language="ja"
            )

            return transcript.text.strip()

        except Exception as e:
            logger.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    async def generate_response(self, user_text: str) -> str:
        """AIå¿œç­”ç”Ÿæˆ"""
        try:
            print("ğŸ¤– AIå¿œç­”ç”Ÿæˆä¸­...")

            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            self.conversation_history.append({"role": "user", "content": user_text})

            # å±¥æ­´ç®¡ç†ï¼ˆæœ€æ–°20ä»¶ä¿æŒï¼‰
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]

            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            system_prompt = """ã‚ãªãŸã¯é«˜é½¢è€…å‘ã‘ã®å„ªã—ã„ä¼šè©±ç›¸æ‰‹ã§ã™ã€‚

ã€é‡è¦ã€‘
- è¦ªã—ã¿ã‚„ã™ãã€æ¸©ã‹ã„è©±ã—æ–¹
- ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ï¼ˆ1-2æ–‡ç¨‹åº¦ï¼‰
- ç›¸æ‰‹ã®æ°—æŒã¡ã«å¯„ã‚Šæ·»ã†
- ä½“èª¿ã‚„æ°—åˆ†ã‚’è‡ªç„¶ã«ç¢ºèª
- ç›¸æ‰‹ã®ãƒšãƒ¼ã‚¹ã«åˆã‚ã›ã‚‹

åˆå›ã¯è»½ã„æŒ¨æ‹¶ã‹ã‚‰å§‹ã‚ã¦ã€å¾ã€…ã«å®‰å¦ç¢ºèªã«ã¤ãªã’ã¦ãã ã•ã„ã€‚"""

            messages = [{"role": "system", "content": system_prompt}] + self.conversation_history

            # GPT-4oå¿œç­”ç”Ÿæˆ
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=100,
                temperature=0.8
            )

            ai_text = response.choices[0].message.content.strip()

            # å±¥æ­´ã«è¿½åŠ 
            self.conversation_history.append({"role": "assistant", "content": ai_text})

            return ai_text

        except Exception as e:
            logger.error(f"AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {e}")
            return "ã™ã¿ã¾ã›ã‚“ã€ã‚ˆãèã“ãˆã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©±ã—ãã ã•ã„ã€‚"

    async def speak_text(self, text: str):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã§å†ç”Ÿ"""
        try:
            print("ğŸ”Š éŸ³å£°ç”Ÿæˆä¸­...")

            # TTSç”Ÿæˆ
            response = self.client.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=text,
                response_format="mp3"
            )

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_audio:
                temp_audio.write(response.content)
                temp_audio_path = temp_audio.name

            print("ğŸ”Š éŸ³å£°å†ç”Ÿä¸­...")

            # macOSã®afplayã§å†ç”Ÿ
            if os.system("which afplay > /dev/null 2>&1") == 0:
                process = await asyncio.create_subprocess_exec(
                    'afplay', temp_audio_path,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await process.wait()
            else:
                # Linuxã®å ´åˆã¯mpg123ã‚’è©¦è¡Œ
                process = await asyncio.create_subprocess_exec(
                    'mpg123', temp_audio_path,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await process.wait()

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(temp_audio_path)
            print("âœ… éŸ³å£°å†ç”Ÿå®Œäº†")

        except Exception as e:
            logger.error(f"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

    def is_end_command(self, text: str) -> bool:
        """çµ‚äº†ã‚³ãƒãƒ³ãƒ‰åˆ¤å®š"""
        end_phrases = [
            "çµ‚äº†", "ãŠã‚ã‚Š", "ãƒã‚¤ãƒã‚¤", "ã•ã‚ˆã†ãªã‚‰",
            "ã‚‚ã†ã„ã„", "ã‚„ã‚ã‚‹", "ã‚¹ãƒˆãƒƒãƒ—", "çµ‚ã‚ã‚Š",
            "ã¾ãŸä»Šåº¦", "ã¾ãŸã­"
        ]
        return any(phrase in text for phrase in end_phrases)

    async def run_conversation(self):
        """ä¼šè©±ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.running = True

        print("ğŸŒ¸ éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        print("ğŸ’¡ è‡ªå‹•ã§é–‹å§‹ã—ã¾ã™...")

        # é–‹å§‹æŒ¨æ‹¶
        current_hour = datetime.now().hour
        if 6 <= current_hour < 12:
            greeting = "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚ä»Šæ—¥ã®èª¿å­ã¯ã„ã‹ãŒã§ã™ã‹ï¼Ÿ"
        elif 12 <= current_hour < 18:
            greeting = "ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯ã„ã‹ãŒãŠéã”ã—ã§ã™ã‹ï¼Ÿ"
        else:
            greeting = "ã“ã‚“ã°ã‚“ã¯ã€‚ä»Šæ—¥ä¸€æ—¥ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚"

        print(f"ğŸ¤– AI: {greeting}")
        await self.speak_text(greeting)

        conversation_count = 0

        try:
            while self.running:
                # éŸ³å£°ã‚’èã
                audio_data = await self.listen_for_speech()

                if audio_data:
                    # éŸ³å£°èªè­˜
                    user_text = await self.transcribe_audio(audio_data)

                    if user_text:
                        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_text}")
                        conversation_count += 1

                        # çµ‚äº†ã‚³ãƒãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯
                        if self.is_end_command(user_text):
                            goodbye = "ãŠè©±ã—ã§ãã¦è‰¯ã‹ã£ãŸã§ã™ã€‚ã¾ãŸä»Šåº¦ãŠè©±ã—ã—ã¾ã—ã‚‡ã†ã€‚ãŠä½“ã«æ°—ã‚’ã¤ã‘ã¦ãã ã•ã„ã­ã€‚"
                            print(f"ğŸ¤– AI: {goodbye}")
                            await self.speak_text(goodbye)
                            break

                        # AIå¿œç­”ç”Ÿæˆ
                        ai_response = await self.generate_response(user_text)
                        print(f"ğŸ¤– AI: {ai_response}")

                        # éŸ³å£°ã§å¿œç­”
                        await self.speak_text(ai_response)

                        # é•·æ™‚é–“ä¼šè©±ã®å ´åˆã¯è‡ªç„¶ã«çµ‚äº†ææ¡ˆ
                        if conversation_count >= 8:
                            ending_suggestion = "ãŸãã•ã‚“ãŠè©±ã—ã§ãã¦æ¥½ã—ã‹ã£ãŸã§ã™ã€‚ä»Šæ—¥ã¯ã“ã®ã‚ãŸã‚Šã§ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿ"
                            print(f"ğŸ¤– AI: {ending_suggestion}")
                            await self.speak_text(ending_suggestion)
                            conversation_count = 0  # ãƒªã‚»ãƒƒãƒˆ

                    else:
                        print("âš ï¸ éŸ³å£°ãŒèªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")

                else:
                    print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

        except KeyboardInterrupt:
            print("\nğŸ›‘ Ctrl+Cã§çµ‚äº†")
        finally:
            self.running = False
            self.audio.terminate()

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ¤" + "="*50)
    print("  ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ")
    print("  Whisper + GPT-4o + TTS")
    print("="*52 + "ğŸ¤")

    chat = SimpleVoiceChat()
    await chat.run_conversation()

    print("\nâœ… ä¼šè©±çµ‚äº†")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")